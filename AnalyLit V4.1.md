# **AnalyLit V4.1 \- Guide Technique Exhaustif**

Ce document fournit une description technique d√©taill√©e de l'architecture, des composants, des flux de donn√©es et des fonctions cl√©s de l'application AnalyLit V4.1. Il est destin√© aux d√©veloppeurs souhaitant comprendre, maintenir ou √©tendre le syst√®me.

## **1\. Architecture et Philosophie**

AnalyLit est une application web conteneuris√©e avec Docker, con√ßue pour l'analyse de litt√©rature scientifique assist√©e par IA. Son architecture repose sur plusieurs principes cl√©s :

* **D√©couplage des Services** : Chaque composant majeur (serveur web, workers, IA, base de donn√©es) est un service ind√©pendant, ce qui facilite la maintenance, le scaling et le remplacement de parties sp√©cifiques.  
* **Traitement Asynchrone** : Les t√¢ches longues sont d√©l√©gu√©es √† des workers en arri√®re-plan via une file d'attente, garantissant une interface utilisateur toujours r√©active.  
* **Persistance des Donn√©es** : Les donn√©es critiques (projets, PDF, bases de donn√©es) sont stock√©es dans des volumes Docker, les s√©parant du cycle de vie des conteneurs.  
* **IA Locale d'Abord** : L'int√©gration avec Ollama permet d'utiliser des mod√®les de langage puissants en local, assurant la confidentialit√© des donn√©es et l'ind√©pendance vis-√†-vis des API cloud.

### **1.1. Composants D√©taill√©s**

* **nginx (Reverse Proxy)** : Point d'entr√©e unique (localhost:8080).  
  * **R√¥le** : Sert les fichiers statiques de l'interface (/web) et agit comme un r√©partiteur de charge et un point de terminaison s√©curis√©.  
  * **Configuration (nginx\_complete.conf)** :  
    * location / : Sert le index.html et les autres fichiers statiques. La directive try\_files est essentielle pour une application monopage (SPA), car elle redirige toutes les routes inconnues vers index.html.  
    * location /api/ : Transf√®re toutes les requ√™tes API au service web sur son port interne (web:5001).  
    * location /socket.io/ : G√®re la connexion WebSocket, en s'assurant que les en-t√™tes Upgrade et Connection sont correctement transmis pour maintenir la connexion ouverte.  
* **web (Serveur Backend Flask)** : Le cerveau de l'application.  
  * **R√¥le** : G√©rer la logique m√©tier, les sessions utilisateur (implicites), la communication avec la base de donn√©es et l'orchestration des t√¢ches de fond.  
  * **Frameworks** : Utilise **Flask** pour l'API REST, **Flask-SocketIO** pour la communication temps r√©el, et **Gunicorn** avec des workers gevent pour un serveur de production performant et non bloquant.  
* **worker (T√¢ches de Fond RQ)** : Les "chevaux de trait" de l'application.  
  * **R√¥le** : Ex√©cuter toutes les op√©rations qui prendraient plus de quelques secondes.  
  * **Framework** : Utilise **Redis Queue (RQ)**, une biblioth√®que Python simple et robuste pour la mise en file d'attente de t√¢ches. Les workers √©coutent en permanence les nouvelles t√¢ches sur les files Redis.  
* **redis (Broker de Messages & Cache)** : Le syst√®me nerveux central.  
  * **R√¥le** : Stocker les listes de t√¢ches √† effectuer pour les workers et servir de bus de communication pour les notifications WebSocket entre les services.  
* **ollama (Serveur d'IA)** : Le moteur d'intelligence artificielle.  
  * **R√¥le** : Charger les mod√®les de langage (LLM) en m√©moire (GPU si disponible) et exposer une API simple pour l'inf√©rence (g√©n√©ration de texte).  
* **projects/ (Volume de Donn√©es)** : La m√©moire persistante de l'application.  
  * database.db : Base de donn√©es **SQLite** unique contenant toutes les m√©tadonn√©es. Le mode journal\_mode=WAL est activ√© pour permettre une meilleure concurrence entre les lectures et les √©critures.  
  * \<project\_id\>/ : Chaque projet a son propre sous-dossier contenant :  
    * Les fichiers PDF import√©s.  
    * Les images g√©n√©r√©es (PRISMA, graphes).  
    * Un dossier chroma\_db/ pour la base de donn√©es vectorielle sp√©cifique √† ce projet.

## **2\. Sch√©ma de la Base de Donn√©es (SQLite)**

La base de donn√©es est con√ßue pour √™tre simple et relationnelle, centr√©e autour du concept de projet.

* **projects** : Table principale. Chaque ligne repr√©sente un projet d'analyse.  
  * id, name, description : Informations de base.  
  * status : √âtat actuel du projet (processing, completed, failed).  
  * analysis\_mode : screening ou full\_extraction.  
  * synthesis\_result, discussion\_draft, etc. : Champs TEXT (JSON) pour stocker les r√©sultats des analyses.  
* **search\_results** : Stocke les m√©tadonn√©es de tous les articles trouv√©s ou ajout√©s √† un projet.  
  * project\_id, article\_id (PMID/DOI), title, abstract, etc.  
* **extractions** : Table la plus importante, stocke les r√©sultats de l'analyse IA pour chaque article.  
  * relevance\_score, relevance\_justification : Pour le mode screening.  
  * extracted\_data : Un champ TEXT contenant le JSON des donn√©es extraites en mode full\_extraction.  
  * user\_validation\_status : include ou exclude, d√©fini par l'utilisateur.  
  * **analysis\_source** : Champ crucial qui trace si l'analyse a √©t√© faite sur le 'pdf' ou l''abstract'.  
* **extraction\_grids**, **analysis\_profiles**, **prompts** : Tables de configuration pour la personnalisation.  
* **chat\_messages** : Stocke l'historique des conversations pour la fonction de Chat RAG.

## **3\. D√©pendances Cl√©s et Leurs R√¥les (requirements.txt)**

La stabilit√© de l'application d√©pend de versions sp√©cifiques de biblioth√®ques Python.

* **Serveur Web & Asynchrone** :  
  * Flask, Flask-CORS, Flask-SocketIO : Forment la base du serveur web et de la communication temps r√©el.  
  * gunicorn, gevent, gevent-websocket : Permettent de faire tourner le serveur Flask de mani√®re performante en production, en g√©rant de multiples connexions simultan√©es sans blocage.  
* **T√¢ches de Fond** :  
  * redis, rq : Le duo qui forme le syst√®me de file d'attente. redis est le serveur de messages, rq est la librairie Python qui permet de cr√©er et de g√©rer les t√¢ches.  
* **IA & NLP** :  
  * sentence-transformers : Utilis√©e pour cr√©er les embeddings (vecteurs num√©riques) √† partir du texte des PDF. Le mod√®le all-MiniLM-L6-v2 est choisi pour son excellent rapport performance/taille.  
  * chromadb : La base de donn√©es vectorielle qui stocke les embeddings et permet la recherche de similarit√© s√©mantique pour le Chat RAG.  
  * langchain : Utilis√©e sp√©cifiquement pour son RecursiveCharacterTextSplitter, un outil efficace pour d√©couper le texte en chunks s√©mantiquement coh√©rents.  
* **API Externes & Traitement de Donn√©es** :  
  * requests : Pour tous les appels HTTP externes.  
  * pyzotero : Client Python pour interagir avec l'API Zotero.  
  * PyPDF2 : Librairie pour extraire le texte brut des fichiers PDF.  
  * pandas, numpy, matplotlib : Utilis√©s pour les analyses statistiques et la g√©n√©ration de graphiques.

## **4\. Description D√©taill√©e des Fonctions Cl√©s**

### **tasks\_v4\_complete.py (Logique M√©tier)**

Ce fichier est le plus critique car il contient la logique de toutes les t√¢ches asynchrones.

* #### **process\_single\_article\_task(...)**   **C'est la fonction la plus complexe, au c≈ìur du pipeline d'analyse.**

  * **Objectif** : Analyser un seul article en utilisant la meilleure source de texte disponible.  
  * **Flux d'Ex√©cution** :  
    1. R√©cup√®re les m√©tadonn√©es de l'article depuis la table search\_results.  
    2. **Cherche un fichier PDF** correspondant √† l'ID de l'article dans le dossier du projet.  
    3. **Si un PDF est trouv√©**, son texte est extrait. Si le texte est de longueur suffisante, la variable analysis\_source est d√©finie sur 'pdf'.  
    4. **Sinon (pas de PDF ou PDF illisible)**, la fonction se rabat sur le r√©sum√© (abstract) et analysis\_source est d√©fini sur 'abstract'.  
    5. Selon l'analysis\_mode du projet :  
       * **screening** : Construit un prompt demandant un score de pertinence.  
       * **full\_extraction** : Construit un prompt plus complexe incluant la structure JSON de la grille d'extraction (personnalis√©e ou par d√©faut).  
    6. Appelle call\_ollama\_api pour obtenir une r√©ponse de l'IA.  
    7. **Sauvegarde le r√©sultat** dans la table extractions, en incluant le score, la justification, les donn√©es extraites, et surtout, la valeur de analysis\_source.

* #### **import\_from\_zotero\_file\_task(...)**

  * **Objectif** : Importer des articles et leurs PDF de mani√®re fiable √† partir d'un export Zotero.  
  * **Flux d'Ex√©cution** :  
    1. Prend en entr√©e le contenu d'un fichier CSL JSON.  
    2. **Analyse l'URL id du premier article** pour d√©tecter automatiquement si la collection provient d'une biblioth√®que personnelle (/users/...) ou de groupe (/groups/...).  
    3. Initialise la connexion √† l'API Zotero avec le bon type et ID de biblioth√®que.  
    4. Parcourt chaque article du fichier JSON :  
       * Ajoute les m√©tadonn√©es de l'article √† la table search\_results s'il n'y est pas d√©j√†.  
       * **Extrait la cl√© d'item Zotero** (ex: M7YXBXKR) de la fin de l'URL id.  
       * Utilise cette cl√© pour appeler zot.children(key), une m√©thode API tr√®s pr√©cise pour lister les fichiers attach√©s.  
       * Si un PDF est trouv√©, il est t√©l√©charg√©.

* #### **index\_project\_pdfs\_task(...) et answer\_chat\_question\_task(...)**   **Ces deux fonctions forment le syst√®me de Retrieval-Augmented Generation (RAG).**

  * **index\_project\_pdfs\_task (L'Indexation)** :  
    1. Utilise PyPDF2 pour extraire le texte brut de tous les PDF du projet.  
    2. Utilise RecursiveCharacterTextSplitter (de LangChain) pour d√©couper intelligemment le texte en morceaux qui se chevauchent (chunks).  
    3. Pour chaque chunk, le mod√®le SentenceTransformer (all-MiniLM-L6-v2) le transforme en un **vecteur num√©rique** (embedding) qui repr√©sente son sens s√©mantique.  
    4. Ces vecteurs, ainsi que le texte original et les m√©tadonn√©es (de quel article vient le chunk), sont stock√©s dans une base de donn√©es vectorielle **ChromaDB**.  
  * **answer\_chat\_question\_task (La R√©ponse)** :  
    1. La question de l'utilisateur est transform√©e en vecteur avec le m√™me mod√®le.  
    2. ChromaDB est interrog√© pour trouver les N chunks de texte dont les vecteurs sont les plus "proches" de celui de la question (recherche de similarit√© cosinus).  
    3. Un **prompt contextuel** est construit, contenant la question de l'utilisateur et les chunks de texte pertinents trouv√©s.  
    4. Ce prompt est envoy√© √† un LLM puissant (comme Llama3.1) avec l'instruction de r√©pondre **uniquement** sur la base du contexte fourni.  
    5. La r√©ponse et les sources sont sauvegard√©es et renvoy√©es √† l'utilisateur.

### **app.js (Logique Frontend)**

* #### **appState**

  * **R√¥le** : Agit comme une "source unique de v√©rit√©" pour l'√©tat de l'interface. Toute donn√©e dynamique (projets, r√©sultats, etc.) est stock√©e ici. Les fonctions de rendu lisent cet √©tat pour dessiner l'interface.

* #### **initializeApplication() et setupEventListeners()**

  * **R√¥le** : Mettre en place l'application. initializeApplication est le point d'entr√©e qui appelle les autres fonctions de chargement. setupEventListeners est crucial car il attache toutes les fonctions de gestion d'√©v√©nements aux √©l√©ments du DOM, en utilisant un syst√®me centralis√© bas√© sur l'attribut data-action.

* #### **Fonctions render...()**

  * **R√¥le** : G√©n√©rer le HTML dynamique. Par exemple, renderProjectArticlesList boucle sur la liste des articles dans appState et cr√©e un \<li\> pour chacun, en y ajoutant la logique pour afficher le bouton üìÑ ou ‚ûï selon la pr√©sence du PDF.

* #### **Fonctions handle...()**

  * **R√¥le** : Contenir la logique m√©tier c√¥t√© client. Par exemple, handleDeleteSelectedArticles :  
    1. R√©cup√®re toutes les cases √† cocher s√©lectionn√©es.  
    2. Extrait les data-article-id de ces cases.  
    3. Affiche une bo√Æte de dialogue de confirmation.  
    4. Utilise fetchAPI pour envoyer la liste des IDs √† supprimer √† l'endpoint backend /api/projects/.../delete-articles.  
    5. Apr√®s confirmation du backend, appelle selectProject(..., true) pour rafra√Æchir les donn√©es et l'affichage.

## **5\. Liens entre les Fichiers et Logique Applicative**

Pour comprendre comment les diff√©rents fichiers collaborent, suivons le parcours d'une action utilisateur typique : **lancer une analyse sur une liste d'articles**.

**Objectif :** L'utilisateur a une liste de PMIDs, il veut que l'IA les analyse en mode "Screening" et voir les r√©sultats.

**√âtape 1 : Interaction Utilisateur (Frontend)**

* **Fichiers impliqu√©s :** index.html, app.js  
* **Logique :**  
  1. L'utilisateur navigue vers l'onglet "Import PDF". La fonction renderImportSection() dans app.js g√©n√®re le HTML n√©cessaire.  
  2. Il colle sa liste de PMIDs dans le \<textarea id="manualPmidTextarea"\>.  
  3. Il clique sur le bouton "Importer via Zotero (Liste)". Ce bouton a un attribut data-action="import-zotero-list".  
  4. La fonction setupEventListeners() dans app.js intercepte ce clic. Elle trouve l'action import-zotero-list dans son objet actions et ex√©cute la fonction associ√©e : handleImportZotero(projectId).

**√âtape 2 : Requ√™te API (Frontend ‚Üí Nginx ‚Üí Backend)**

* **Fichiers impliqu√©s :** app.js, nginx\_complete.conf, server\_v4\_complete.py  
* **Logique :**  
  1. handleImportZotero() dans app.js r√©cup√®re la liste des PMIDs depuis le textarea.  
  2. Elle appelle fetchAPI('/projects/.../import-zotero', { method: 'POST', ... }).  
  3. Le navigateur envoie une requ√™te POST √† http://localhost:8080/api/projects/.../import-zotero.  
  4. **Nginx** (nginx\_complete.conf) re√ßoit la requ√™te. Comme elle correspond √† location /api/, il la transf√®re au service backend d√©fini comme upstream analylit\_backend, c'est-√†-dire web:5001.  
  5. Le serveur **Flask** (server\_v4\_complete.py) re√ßoit la requ√™te sur la route @api\_bp.route('/projects/\<project\_id\>/import-zotero', methods=\['POST'\]).

**√âtape 3 : Mise en File de la T√¢che (Backend ‚Üí Redis)**

* **Fichiers impliqu√©s :** server\_v4\_complete.py, tasks\_v4\_complete.py, redis  
* **Logique :**  
  1. La fonction import\_from\_zotero() dans server\_v4\_complete.py r√©cup√®re les donn√©es JSON de la requ√™te.  
  2. Elle appelle la fonction add\_manual\_articles\_to\_project() pour ajouter les m√©tadonn√©es des nouveaux articles √† la base de donn√©es.  
  3. Ensuite, elle met en file une t√¢che pour le worker : background\_queue.enqueue(import\_pdfs\_from\_zotero\_task, ...).  
  4. La librairie RQ s√©rialise la fonction et ses arguments et les place dans une file d'attente sur le serveur **Redis**.  
  5. Le serveur web renvoie imm√©diatement une r√©ponse 202 Accepted au frontend, indiquant que la t√¢che a √©t√© accept√©e pour traitement.

**√âtape 4 : Ex√©cution de la T√¢che (Worker)**

* **Fichiers impliqu√©s :** worker (conteneur), tasks\_v4\_complete.py, config\_v4.py, ollama  
* **Logique :**  
  1. Un conteneur worker est en attente de nouvelles t√¢ches sur les files Redis.  
  2. Il r√©cup√®re la t√¢che import\_pdfs\_from\_zotero\_task et ses arguments.  
  3. La fonction s'ex√©cute. Elle utilise les variables d'environnement (comme ZOTERO\_API\_KEY) et les param√®tres de config\_v4.py.  
  4. Elle se connecte √† l'API Zotero, cherche chaque article, et t√©l√©charge les PDF trouv√©s dans le volume projects/.  
  5. Pendant son ex√©cution, la t√¢che peut appeler send\_project\_notification(...).

**√âtape 5 : Notification en Temps R√©el (Worker ‚Üí Redis ‚Üí Backend ‚Üí Frontend)**

* **Fichiers impliqu√©s :** tasks\_v4\_complete.py, redis, server\_v4\_complete.py, app.js  
* **Logique :**  
  1. La fonction send\_project\_notification() dans tasks\_v4\_complete.py se connecte √† Redis et publie un message sur un canal pub/sub.  
  2. Le serveur web (server\_v4\_complete.py), via Flask-SocketIO, est abonn√© √† ce canal Redis. Il re√ßoit le message.  
  3. Le serveur web relaie ce message via la connexion WebSocket au client concern√© (gr√¢ce au syst√®me de "room").  
  4. Dans app.js, la fonction initializeWebSocket() a d√©fini un √©couteur socket.on('notification', ...) qui re√ßoit le message.  
  5. La fonction handleWebSocketNotification() est appel√©e. Elle affiche un "toast" et peut d√©clencher un rafra√Æchissement des donn√©es en appelant selectProject(..., true).

**√âtape 6 : Finalisation et Mise √† Jour de l'UI**

* **Fichiers impliqu√©s :** tasks\_v4\_complete.py, app.js, index.html  
* **Logique :**  
  1. √Ä la fin de son ex√©cution, la t√¢che import\_pdfs\_from\_zotero\_task envoie une notification finale 'zotero\_import\_completed'.  
  2. Le frontend re√ßoit cette notification et rafra√Æchit les donn√©es du projet.  
  3. selectProject(..., true) est appel√©, ce qui refait un fetchAPI pour obtenir les derni√®res informations du projet.  
  4. Enfin, renderImportSection() et renderProjectArticlesList() sont appel√©es √† nouveau. Elles lisent le appState mis √† jour et redessinent l'interface, affichant maintenant l'ic√¥ne üìÑ √† c√¥t√© des articles dont le PDF a √©t√© import√© avec succ√®s.

Ce cycle complet, du clic √† la mise √† jour de l'interface, illustre comment les diff√©rents composants et fichiers de l'application sont interconnect√©s pour fournir une exp√©rience utilisateur fluide et asynchrone.

## **6\. D√©ploiement et Maintenance**

* **D√©ploiement** : Le d√©ploiement est enti√®rement g√©r√© par docker-compose. La commande docker-compose up \-d \--build suffit √† construire les images et lancer tous les services dans le bon ordre.  
* **Mise √† jour** : Pour mettre √† jour l'application, il suffit de r√©cup√©rer la derni√®re version du code (git pull), puis de relancer la commande de d√©ploiement. Docker reconstruira uniquement les images dont les fichiers ont chang√©.  
* **Sauvegardes** : La partie la plus critique √† sauvegarder est le volume projects/. Une simple compression de ce dossier (tar \-czf backup.tar.gz projects/) suffit pour sauvegarder toutes les donn√©es des utilisateurs. Les mod√®les Ollama peuvent √™tre ret√©l√©charg√©s.  
* **Monitoring** : La commande docker-compose logs \-f est l'outil principal pour suivre l'activit√© de l'application en temps r√©el. Pour les performances, docker stats donne un aper√ßu de l'utilisation CPU et RAM de chaque conteneur.

## **7\. Pistes d'Am√©lioration et Extensibilit√©**

L'architecture modulaire de l'application permet de nombreuses extensions futures :

* **Ajout de nouvelles bases de donn√©es** : Il suffit d'ajouter une nouvelle m√©thode search\_... dans la classe DatabaseManager de tasks\_v4\_complete.py et de l'appeler dans la t√¢che multi\_database\_search\_task.  
* **Support de nouveaux types d'analyses** : Une nouvelle carte peut √™tre ajout√©e dans renderAnalysisSection() (app.js), li√©e √† un nouvel endpoint dans server\_v4\_complete.py, qui lui-m√™me mettra en file une nouvelle t√¢che d'analyse dans tasks\_v4\_complete.py.  
* **Authentification multi-utilisateurs** : Le sch√©ma de la base de donn√©es peut √™tre √©tendu avec une table users, et les requ√™tes peuvent √™tre modifi√©es pour filtrer les projets par user\_id.  
* **Mod√®les d'IA Cloud** : La fonction call\_ollama\_api pourrait √™tre √©tendue pour appeler, en alternative, des API comme GPT-4 ou Claude, en se basant sur la configuration du profil d'analyse.